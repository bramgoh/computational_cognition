---
title: "Discrepancy Encoding in MINERVA (Part 1)"
author: "Bram Goh"
date: "2023-03-08"
categories: [code]
image: ""
---

# Applying discrepancy encoding to frequency judgments

The goal of this exploration is to look into how the discrepancy encoding assumption introduced in MINERVA-AL (Jamieson et al., 2012) affects Hintzman's (1988) frequency judgment simulations.

```{r}
library(tidyverse)
set.seed(30)

# Activation function (borrowed from Matt) for a single probe (i.e. a probe vector)

get_activations_3 <- function(probe, mem) {
  
  as.numeric(((probe %*% t(mem)) / rowSums(t((probe == 0) * t(mem == 0)) == 0))^3)
}

# Generate echo (borrowed from Matt)
get_echo <- function(probe, mem, tau=3, output='intensity') {
    activations <- get_activations_3(probe,mem)
    if(output == "intensity"){
      return(sum(activations^tau))
    }
    if(output == "echo"){
      weighted_memory <- mem * (activations^tau)  
      summed_echo <- colSums(weighted_memory)
      return(summed_echo)
    }
    if(output == "both"){
      weighted_memory <- mem * (activations^tau)  
      summed_echo <- colSums(weighted_memory)
      model_output <- list(intensity = sum(activations^tau),
                           echo = summed_echo)
      return(model_output)
    }
    
}

# Item generation function (borrowed from Matt)

generate_item <- function(item_size=20,prob=c(1/3,1/3,1/3)){
  item <- sample(c(1,0,-1),
           size = item_size,
           replace = TRUE,
           prob = prob)
  return(item)
}

# Item matrix (original, before applying learning rate) function

gen_item_matrix <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3)) {
  item_matrix <- t(replicate(n = matrix_size, generate_item(item_size = item_size, prob = prob)))
  return(item_matrix)
}

# Form probe matrix i.e. item_matrix multiplied by respective frequencies + 4 more random items

gen_probes <- function(item_matrix, prob = c(1/3, 1/3, 1/3), max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  freq_multiplier <- rep(1:max_num_of_copies, each = num_of_traces_per_freq)
  probe_matrix <- c()
  for(i in 1:length(freq_multiplier)) {
    current_rows <- matrix(rep(item_matrix[i, ], freq_multiplier[i]), nrow = freq_multiplier[i], ncol = ncol(item_matrix), byrow = TRUE)
    probe_matrix <- rbind(probe_matrix, current_rows)
}
  return(probe_matrix)
}

```

```{r}
# Overall simulation function (no discrepancy encoding)

sim_intensity_once <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)
  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)

  # Starting state secondary memory
memory <- t(replicate(n = 60, generate_item(item_size = 20, prob = c(1/3, 1/3, 1/3))))

# Caluclating intensities and storing each probe
intensity_vector <- numeric(length = nrow(probe_matrix))
  for(i in 1:nrow(probe_matrix)){
    current_intensity <- get_echo(probe_matrix[i, ], memory, output = "intensity")
    intensity_vector[i] <- current_intensity
    learning_filter <- sample(c(0, 1), item_size, replace = TRUE, prob = c(1-l_value, l_value))
    learned_probe <- probe_matrix[i, ] * learning_filter
    memory[i, ] <- learned_probe
  }
intensity_df <- data.frame(intensity_value = intensity_vector)
return(intensity_df)
}

sim_intensity_multiple <- function(n_of_sim, matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  full_intensity_df <- data.frame(matrix(0, nrow = sum((1:max_num_of_copies)*4), ncol = n_of_sim))
  for(i in 1:n_of_sim) {
    intensity_column <- sim_intensity_once(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
    full_intensity_df[ , i] <- intensity_column
  }
  return(full_intensity_df)
}
```

```{r}
raw_df_no_de <- sim_intensity_multiple(100)

by_probe_no_de <- data.frame(probe_no = 1:60, intensity = rowMeans(raw_df_no_de))
ggplot(by_probe_no_de, aes(x = probe_no, y = intensity)) + geom_line() + coord_cartesian(ylim = c(-0.01, 0.075)) + scale_x_continuous(breaks = seq(1, 60, 2)) + geom_vline(xintercept = c(5, 13, 25, 41), color = "red")

by_freq_no_de <- data.frame(frequency = rep(c(1,2,3,4,5), each = 4), raw_df_no_de) %>% group_by(frequency) %>% summarize_all(mean) %>% pivot_longer(!frequency, names_to = "Drop", values_to = "Intensity") %>% select(-Drop)
ggplot(by_freq_no_de, aes(x = Intensity, color = factor(frequency))) + geom_density(show.legend = TRUE) + coord_cartesian(xlim = c(-0.01, 0.05))
```

```{r}

# Overall simulation function (with discrepancy encoding)

sim_intensity_once_de <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)
  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)

  # Starting state secondary memory
memory <- t(replicate(n = 60, generate_item(item_size = 20, prob = c(1/3, 1/3, 1/3))))

# Caluclating intensities and storing each probe
intensity_vector <- numeric(length = nrow(probe_matrix))
  for(i in 1:nrow(probe_matrix)){
    current_echo <- get_echo(probe_matrix[i, ], memory, output = "both")
    intensity_vector[i] <- current_echo[[1]]
    learning_filter <- sample(c(0, 1), item_size, replace = TRUE, prob = c(1-l_value, l_value))
    current_content <- current_echo[[2]]/max(current_echo[[2]])
    discrep <- probe_matrix[i, ] - current_content
    learned_trace <- discrep * learning_filter
    memory[i, ] <- learned_trace
  }
intensity_df <- data.frame(intensity_value = intensity_vector)
return(intensity_df)
}

sim_intensity_multiple_de <- function(n_of_sim, matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  full_intensity_df <- data.frame(matrix(0, nrow = sum((1:max_num_of_copies)*4), ncol = n_of_sim))
  for(i in 1:n_of_sim) {
    intensity_column <- sim_intensity_once_de(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
    full_intensity_df[ , i] <- intensity_column
  }
  return(full_intensity_df)
}
```

```{r}
raw_df_with_de <- sim_intensity_multiple_de(100)

by_probe_with_de <- data.frame(probe_no = 1:60, intensity = rowMeans(raw_df_with_de))
ggplot(by_probe_with_de, aes(x = probe_no, y = intensity)) + geom_line() + scale_x_continuous(breaks = seq(1, 60, 2)) + geom_vline(xintercept = c(5, 13, 25, 41), color = "red")

by_freq_with_de <- data.frame(frequency = rep(c(1,2,3,4,5), each = 4), raw_df_with_de) %>% group_by(frequency) %>% summarize_all(mean) %>% pivot_longer(!frequency, names_to = "Drop", values_to = "Intensity") %>% select(-Drop)
ggplot(by_freq_with_de, aes(x = Intensity, color = factor(frequency))) + geom_density(show.legend = TRUE) + coord_cartesian(xlim = c(-0.0025, 0.0025))
```
