---
title: "Hintzman's (1988) MINERVA (Part 2)"
author: "Bram Goh"
date: "2023-02-17"
categories: [code]
image: "frequency_discrim.png"
---

# Applying MINERVA 2 to frequency judgment tasks

## Absolute Frequency Judgments

### Code from previous exercise

```{r}
library(tidyverse)
set.seed(30)

# Activation function (borrowed from Matt) for a single probe (i.e. a probe vector)

get_activations_3 <- function(probe, mem) {
  
  as.numeric(((probe %*% t(mem)) / rowSums(t((probe == 0) * t(mem == 0)) == 0))^3)
}

# Item generation function (borrowed from Matt)

generate_item <- function(item_size=20,prob=c(1/3,1/3,1/3)){
  item <- sample(c(1,0,-1),
           size = item_size,
           replace = TRUE,
           prob = prob)
  return(item)
}

# Item matrix (original, before applying learning rate) function

gen_item_matrix <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3)) {
  item_matrix <- t(replicate(n = matrix_size, generate_item(item_size = item_size, prob = prob)))
  return(item_matrix)
}

# Form secondary memory -- create encoded matrix (i.e. apply learning rate) and input varying frequencies of items

gen_secondary_mem <- function(item_matrix, l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  learning_matrix <- replicate(n = ncol(item_matrix), sample(c(0,1), size = nrow(item_matrix), prob = c(1 - l_value, l_value), replace = TRUE))
  encoded_matrix <- item_matrix * learning_matrix
  
  freq_multiplier <- c()
  for (i in 1:max_num_of_copies) {
    current_multiplier <- rep(i, num_of_traces_per_freq)
    freq_multiplier <- c(freq_multiplier, current_multiplier)
  }
  secondary_memory <- c()
  for(i in 1:nrow(encoded_matrix)) {
    current_rows <- matrix(encoded_matrix[i , ], nrow = freq_multiplier[i], ncol = ncol(encoded_matrix), byrow = TRUE)
    secondary_memory <- rbind(secondary_memory, current_rows)
  }
 return(secondary_memory)
}

# Form probe matrix i.e. item_matrix + 4 more random items

gen_probes <- function(item_matrix, prob = c(1/3, 1/3, 1/3), max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  random_items <- t(replicate(n = num_of_traces_per_freq, generate_item(item_size = ncol(item_matrix), prob = prob)))
  probe_matrix <- rbind(random_items, item_matrix)
  return(probe_matrix)
}

# Calculate activations for multiple probes

calc_activs_for_mult_probes <- function(probe_matrix, secondary_memory) {
  activations_matrix <- c()
  for(i in 1:nrow(probe_matrix)) {
    current_activs <- get_activations_3(probe_matrix[i, ], secondary_memory)
    activations_matrix <- rbind(activations_matrix, current_activs)
  }
  return(activations_matrix)
}

# Convert activations matrix to transformed intensity matrix ready for plotting

convert_to_intensity_mat <- function(activations_matrix, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  intensity_vector <- rowSums(activations_matrix)
  intensity_matrix <- matrix(intensity_vector, nrow = max_num_of_copies + 1, ncol = num_of_traces_per_freq, byrow = TRUE)
  return(intensity_matrix)
}
```

```{r}
# Overall simulation function

sim_intensity_once <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)
  secondary_memory <- gen_secondary_mem(item_matrix, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
  activations_matrix <- calc_activs_for_mult_probes(probe_matrix, secondary_memory)
  intensity_matrix <- convert_to_intensity_mat(activations_matrix, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
  return(intensity_matrix)
}

sim_intensity_multiple <- function(n_of_sim, matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  raw_intensity_matrix <- c()
  for(i in 1:n_of_sim) {
    temp_intensity <- sim_intensity_once(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
    raw_intensity_matrix <- cbind(raw_intensity_matrix, temp_intensity)
  }
  row_names <- as.data.frame(0:max_num_of_copies)
  names(row_names) <- "Frequency"
  intensity_df <- bind_cols(row_names, data.frame(raw_intensity_matrix)) %>%
      pivot_longer(!Frequency, names_to = "Drop", values_to = "Intensity") %>% select("Frequency", "Intensity")
  return(intensity_df)
}
```

```{r}

df_intensity <- sim_intensity_multiple(1000)
ggplot(df_intensity, aes(x = Intensity, color = factor(Frequency))) + geom_density(show.legend = TRUE) + xlim(-1, 2)
```

### Code for absolute frequency judgments

```{r}
intensity_df <- sim_intensity_multiple(250, matrix_size = 16, l_value = 0.8, max_num_of_copies = 4)
discrim_intensity_df <- intensity_df %>% mutate(freq_judgement = case_when(
  Intensity < 0.17 ~ 0,
  Intensity >= 0.17 & Intensity < 0.67 ~ 1,
  Intensity >= 0.67 & Intensity < 1.33 ~ 2,
  Intensity >= 1.33 & Intensity < 2 ~ 3,
  Intensity >= 2 ~ 4
))

freq_judgment_df <- data.frame(table(factor(discrim_intensity_df$Frequency, levels = 0:4), factor(discrim_intensity_df$freq_judgement, levels = 0:4))) %>% mutate(Freq = Freq/1000) %>% rename(Real_freq = Var1, Freq_judg = Var2, Proportion_of_resp = Freq)


```

```{r}
ggplot(freq_judgment_df, aes(x = Freq_judg, y = Proportion_of_resp, group = Real_freq, color = Real_freq)) + geom_path() + geom_point()

```

I've reproduced the rough shape of the graph, but the values are lower than in Hintzman's (1988) graph. It is also strange that the proportion of correct responses when frequency = 3 is lower than that for frequency = 4. The general trend of lower peaks as frequency_judgment increases is not reflected in my graph.\

## Effects of orienting (shallow vs deep levels of processing)

```{r}

# Initial parameters

num_feat_shallow <- 10
num_feat_deep <- 15
num_of_traces_per_freq <- 4
max_num_of_copies <- 5

# Creating the appropriate number of copies for each item

gen_item_mat_copies <- function(item_matrix) {
  
  freq_multiplier <- c()
  for (i in 1:max_num_of_copies) {
    current_multiplier <- rep(i, num_of_traces_per_freq)
    freq_multiplier <- c(freq_multiplier, current_multiplier)
  }
  
  item_mat_copies <- c()
  for(i in 1:nrow(item_matrix)) {
    current_rows <- matrix(item_matrix[i , ], nrow = freq_multiplier[i], ncol = ncol(item_matrix), byrow = TRUE)
    item_mat_copies <- rbind(item_mat_copies, current_rows)
  }
 return(item_mat_copies)
}

# Functions for shallow learning filter and deep learning filter

gen_shallow_learning_filter <- function(l_value1 = 0.6, l_value2 = 0) {
  matrix_shallow_part_1 <- sample(c(0,1), size = num_feat_shallow, prob = c(1 - l_value1, l_value1), replace = TRUE)
  matrix_shallow_part_2 <- sample(c(0,1), size = num_feat_deep, prob = c(1 - l_value2, l_value2), replace = TRUE)
  matrix_shallow <- c(matrix_shallow_part_1, matrix_shallow_part_2)
  return(matrix_shallow)
}

gen_deep_learning_filter <- function(l_value1 = 0.6, l_value2 = 0) {
  matrix_deep_part_1 <- sample(c(0,1), size = num_feat_shallow, prob = c(1 - l_value2, l_value2), replace = TRUE)
  matrix_deep_part_2 <- sample(c(0,1), size = num_feat_deep, prob = c(1 - l_value1, l_value1), replace = TRUE)
  matrix_deep <- c(matrix_deep_part_1, matrix_deep_part_2)
  return(matrix_deep)
}

# Generating secondary memory - putting item copies matrix through learning filters

gen_orienting_secondary_mem <- function(item_copies_matrix, l_value1 = 0.6, l_value2 = 0) {
  
orienting_sec_mem <- c()
for(i in 1:nrow(item_copies_matrix)) {
  if(i %% 2 == 0) {
    deep_filter <- gen_deep_learning_filter(l_value1 = l_value1, l_value2 = l_value2)
    orienting_sec_mem <- rbind(orienting_sec_mem, item_copies_matrix[i, ] * deep_filter)
  } else {
  shallow_filter <- gen_shallow_learning_filter(l_value1 = l_value1, l_value2 = l_value2)
    orienting_sec_mem <- rbind(orienting_sec_mem, item_copies_matrix[i, ] * shallow_filter)
    }
}
return(orienting_sec_mem)
}

# Convert activations matrix to intensity matrix (slightly different from previous function)

orient_convert_to_intensity_matrix <- function(activations_matrix, max_num_of_copies = 5, num_of_traces_per_freq = 4) {
  intensity_vector <- rowSums(activations_matrix)
  intensity_matrix <- matrix(intensity_vector, nrow = max_num_of_copies + 1, ncol = num_of_traces_per_freq/2, byrow = TRUE)
  return(intensity_matrix)
}



```

```{r}
# Encode traces into secondary memory
item_mat <- gen_item_matrix(item_size = 25)
item_copies_mat <- gen_item_mat_copies(item_mat)
or_sec_mem <- gen_orienting_secondary_mem(item_copies_mat)
probe_mat <- gen_probes(item_mat)

activ_mat_raw <- calc_activs_for_mult_probes(probe_mat, or_sec_mem)
activ_mat_shallow <- c()
activ_mat_deep <- c()
for(i in 1:nrow(activ_mat_raw)) {
  if(i %% 2 == 0) {
    activ_mat_deep <- rbind(activ_mat_deep, activ_mat_raw[i, ])
  } else {
    activ_mat_shallow <- rbind(activ_mat_shallow, activ_mat_raw[i, ])
  }
}



intensity_shallow <- orient_convert_to_intensity_matrix(activ_mat_shallow)


sim_orienting_once <- function(matrix_size = 20, item_size = 25, prob = c(1/3, 1/3, 1/3), l_value1 = 0.6, l_value2 = 0) {
  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)
  item_matrix_copies <- gen_item_mat_copies(item_matrix)
  orienting_memory <- gen_orienting_secondary_mem(item_matrix_copies, l_value1 = l_value1, l_value2 = l_value2)
  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)
  raw_activations <- calc_activs_for_mult_probes(probe_matrix, orienting_memory)
  
  shallow_activations <- c()
  deep_activations <- c()
  for(i in 1:nrow(raw_activations)) {
  if(i %% 2 == 0) {
    deep_activations <- rbind(deep_activations, raw_activations[i, ])
  } else {
    shallow_activations <- rbind(shallow_activations, raw_activations[i, ])
  }
  }
  intensity_matrix <- rbind(orient_convert_to_intensity_matrix(shallow_activations), orient_convert_to_intensity_matrix(deep_activations))
  return(intensity_matrix)
  }
  

sim_orienting_multiple <- function(n_of_sim, matrix_size = 20, item_size = 25, prob = c(1/3, 1/3, 1/3), l_value1 = 0.6, l_value2 = 0) {
  raw_intensity_matrix <- c()
  for(i in 1:n_of_sim) {
    temp_intensity <- sim_orienting_once(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value1 = l_value1, l_value2 = l_value2)
    raw_intensity_matrix <- cbind(raw_intensity_matrix, temp_intensity)
  }
  level_of_process <- c(rep("shallow", max_num_of_copies + 1), rep("deep", max_num_of_copies + 1))
 frequency <- rep(0:max_num_of_copies, 2)
  intensity_df <- bind_cols(level_of_process, frequency, data.frame(raw_intensity_matrix)) %>% rename(level_of_process = ...1, frequency = ...2) %>% 
    pivot_longer(cols = starts_with("X"), names_to = "Drop", values_to = "Intensity") %>% select(!Drop)
  return(intensity_df)
}
```

```{r}
orient_intensity <- sim_orienting_multiple(1000)
summarized_intensity <- orient_intensity %>% group_by(level_of_process, frequency) %>% summarize(mean_intensity = mean(Intensity))

```

```{r}
ggplot(summarized_intensity, aes(x = frequency, y = mean_intensity, group = level_of_process, color = level_of_process)) + geom_path() + geom_point()
```

This graph is very different from Hintzman's. I think I may have made the same mistake as last time with applying the learning rate before making copies, resulting in identically learnt traces.
