{
  "hash": "f615b186c688c14f04e66d71586f2dbe",
  "result": {
    "markdown": "---\ntitle: \"Hintzman's (1988) MINERVA (Part 2)\"\nauthor: \"Bram Goh\"\ndate: \"2023-02-17\"\ncategories: [code]\nimage: \"frequency_discrim.png\"\n---\n\n\n# Applying MINERVA 2 to frequency judgment tasks\n\n## Absolute Frequency Judgments\n\n### Code from previous exercise\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nset.seed(30)\n\n# Activation function (borrowed from Matt) for a single probe (i.e. a probe vector)\n\nget_activations_3 <- function(probe, mem) {\n  \n  as.numeric(((probe %*% t(mem)) / rowSums(t((probe == 0) * t(mem == 0)) == 0))^3)\n}\n\n# Item generation function (borrowed from Matt)\n\ngenerate_item <- function(item_size=20,prob=c(1/3,1/3,1/3)){\n  item <- sample(c(1,0,-1),\n           size = item_size,\n           replace = TRUE,\n           prob = prob)\n  return(item)\n}\n\n# Item matrix (original, before applying learning rate) function\n\ngen_item_matrix <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3)) {\n  item_matrix <- t(replicate(n = matrix_size, generate_item(item_size = item_size, prob = prob)))\n  return(item_matrix)\n}\n\n# Form secondary memory -- create encoded matrix (i.e. apply learning rate) and input varying frequencies of items\n\ngen_secondary_mem <- function(item_matrix, l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  learning_matrix <- replicate(n = ncol(item_matrix), sample(c(0,1), size = nrow(item_matrix), prob = c(1 - l_value, l_value), replace = TRUE))\n  encoded_matrix <- item_matrix * learning_matrix\n  \n  freq_multiplier <- c()\n  for (i in 1:max_num_of_copies) {\n    current_multiplier <- rep(i, num_of_traces_per_freq)\n    freq_multiplier <- c(freq_multiplier, current_multiplier)\n  }\n  secondary_memory <- c()\n  for(i in 1:nrow(encoded_matrix)) {\n    current_rows <- matrix(encoded_matrix[i , ], nrow = freq_multiplier[i], ncol = ncol(encoded_matrix), byrow = TRUE)\n    secondary_memory <- rbind(secondary_memory, current_rows)\n  }\n return(secondary_memory)\n}\n\n# Form probe matrix i.e. item_matrix + 4 more random items\n\ngen_probes <- function(item_matrix, prob = c(1/3, 1/3, 1/3), max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  random_items <- t(replicate(n = num_of_traces_per_freq, generate_item(item_size = ncol(item_matrix), prob = prob)))\n  probe_matrix <- rbind(random_items, item_matrix)\n  return(probe_matrix)\n}\n\n# Calculate activations for multiple probes\n\ncalc_activs_for_mult_probes <- function(probe_matrix, secondary_memory) {\n  activations_matrix <- c()\n  for(i in 1:nrow(probe_matrix)) {\n    current_activs <- get_activations_3(probe_matrix[i, ], secondary_memory)\n    activations_matrix <- rbind(activations_matrix, current_activs)\n  }\n  return(activations_matrix)\n}\n\n# Convert activations matrix to transformed intensity matrix ready for plotting\n\nconvert_to_intensity_mat <- function(activations_matrix, max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  intensity_vector <- rowSums(activations_matrix)\n  intensity_matrix <- matrix(intensity_vector, nrow = max_num_of_copies + 1, ncol = num_of_traces_per_freq, byrow = TRUE)\n  return(intensity_matrix)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Overall simulation function\n\nsim_intensity_once <- function(matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)\n  secondary_memory <- gen_secondary_mem(item_matrix, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)\n  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)\n  activations_matrix <- calc_activs_for_mult_probes(probe_matrix, secondary_memory)\n  intensity_matrix <- convert_to_intensity_mat(activations_matrix, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)\n  return(intensity_matrix)\n}\n\nsim_intensity_multiple <- function(n_of_sim, matrix_size = 20, item_size = 20, prob = c(1/3, 1/3, 1/3), l_value = .5, max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  raw_intensity_matrix <- c()\n  for(i in 1:n_of_sim) {\n    temp_intensity <- sim_intensity_once(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value = l_value, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)\n    raw_intensity_matrix <- cbind(raw_intensity_matrix, temp_intensity)\n  }\n  row_names <- as.data.frame(0:max_num_of_copies)\n  names(row_names) <- \"Frequency\"\n  intensity_df <- bind_cols(row_names, data.frame(raw_intensity_matrix)) %>%\n      pivot_longer(!Frequency, names_to = \"Drop\", values_to = \"Intensity\") %>% select(\"Frequency\", \"Intensity\")\n  return(intensity_df)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_intensity <- sim_intensity_multiple(1000)\nggplot(df_intensity, aes(x = Intensity, color = factor(Frequency))) + geom_density(show.legend = TRUE) + xlim(-1, 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 255 rows containing non-finite values (stat_density).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### Code for absolute frequency judgments\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintensity_df <- sim_intensity_multiple(250, matrix_size = 16, l_value = 0.8, max_num_of_copies = 4)\ndiscrim_intensity_df <- intensity_df %>% mutate(freq_judgement = case_when(\n  Intensity < 0.17 ~ 0,\n  Intensity >= 0.17 & Intensity < 0.67 ~ 1,\n  Intensity >= 0.67 & Intensity < 1.33 ~ 2,\n  Intensity >= 1.33 & Intensity < 2 ~ 3,\n  Intensity >= 2 ~ 4\n))\n\nfreq_judgment_df <- data.frame(table(factor(discrim_intensity_df$Frequency, levels = 0:4), factor(discrim_intensity_df$freq_judgement, levels = 0:4))) %>% mutate(Freq = Freq/1000) %>% rename(Real_freq = Var1, Freq_judg = Var2, Proportion_of_resp = Freq)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(freq_judgment_df, aes(x = Freq_judg, y = Proportion_of_resp, group = Real_freq, color = Real_freq)) + geom_path() + geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nI've reproduced the rough shape of the graph, but the values are lower than in Hintzman's (1988) graph. It is also strange that the proportion of correct responses when frequency = 3 is lower than that for frequency = 4. The general trend of lower peaks as frequency_judgment increases is not reflected in my graph.\\\n\n## Effects of orienting (shallow vs deep levels of processing)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initial parameters\n\nnum_feat_shallow <- 10\nnum_feat_deep <- 15\nnum_of_traces_per_freq <- 4\nmax_num_of_copies <- 5\n\n# Creating the appropriate number of copies for each item\n\ngen_item_mat_copies <- function(item_matrix) {\n  \n  freq_multiplier <- c()\n  for (i in 1:max_num_of_copies) {\n    current_multiplier <- rep(i, num_of_traces_per_freq)\n    freq_multiplier <- c(freq_multiplier, current_multiplier)\n  }\n  \n  item_mat_copies <- c()\n  for(i in 1:nrow(item_matrix)) {\n    current_rows <- matrix(item_matrix[i , ], nrow = freq_multiplier[i], ncol = ncol(item_matrix), byrow = TRUE)\n    item_mat_copies <- rbind(item_mat_copies, current_rows)\n  }\n return(item_mat_copies)\n}\n\n# Functions for shallow learning filter and deep learning filter\n\ngen_shallow_learning_filter <- function(l_value1 = 0.6, l_value2 = 0) {\n  matrix_shallow_part_1 <- sample(c(0,1), size = num_feat_shallow, prob = c(1 - l_value1, l_value1), replace = TRUE)\n  matrix_shallow_part_2 <- sample(c(0,1), size = num_feat_deep, prob = c(1 - l_value2, l_value2), replace = TRUE)\n  matrix_shallow <- c(matrix_shallow_part_1, matrix_shallow_part_2)\n  return(matrix_shallow)\n}\n\ngen_deep_learning_filter <- function(l_value1 = 0.6, l_value2 = 0) {\n  matrix_deep_part_1 <- sample(c(0,1), size = num_feat_shallow, prob = c(1 - l_value2, l_value2), replace = TRUE)\n  matrix_deep_part_2 <- sample(c(0,1), size = num_feat_deep, prob = c(1 - l_value1, l_value1), replace = TRUE)\n  matrix_deep <- c(matrix_deep_part_1, matrix_deep_part_2)\n  return(matrix_deep)\n}\n\n# Generating secondary memory - putting item copies matrix through learning filters\n\ngen_orienting_secondary_mem <- function(item_copies_matrix, l_value1 = 0.6, l_value2 = 0) {\n  \norienting_sec_mem <- c()\nfor(i in 1:nrow(item_copies_matrix)) {\n  if(i %% 2 == 0) {\n    deep_filter <- gen_deep_learning_filter(l_value1 = l_value1, l_value2 = l_value2)\n    orienting_sec_mem <- rbind(orienting_sec_mem, item_copies_matrix[i, ] * deep_filter)\n  } else {\n  shallow_filter <- gen_shallow_learning_filter(l_value1 = l_value1, l_value2 = l_value2)\n    orienting_sec_mem <- rbind(orienting_sec_mem, item_copies_matrix[i, ] * shallow_filter)\n    }\n}\nreturn(orienting_sec_mem)\n}\n\n# Convert activations matrix to intensity matrix (slightly different from previous function)\n\norient_convert_to_intensity_matrix <- function(activations_matrix, max_num_of_copies = 5, num_of_traces_per_freq = 4) {\n  intensity_vector <- rowSums(activations_matrix)\n  intensity_matrix <- matrix(intensity_vector, nrow = max_num_of_copies + 1, ncol = num_of_traces_per_freq/2, byrow = TRUE)\n  return(intensity_matrix)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Encode traces into secondary memory\nitem_mat <- gen_item_matrix(item_size = 25)\nitem_copies_mat <- gen_item_mat_copies(item_mat)\nor_sec_mem <- gen_orienting_secondary_mem(item_copies_mat)\nprobe_mat <- gen_probes(item_mat)\n\nactiv_mat_raw <- calc_activs_for_mult_probes(probe_mat, or_sec_mem)\nactiv_mat_shallow <- c()\nactiv_mat_deep <- c()\nfor(i in 1:nrow(activ_mat_raw)) {\n  if(i %% 2 == 0) {\n    activ_mat_deep <- rbind(activ_mat_deep, activ_mat_raw[i, ])\n  } else {\n    activ_mat_shallow <- rbind(activ_mat_shallow, activ_mat_raw[i, ])\n  }\n}\n\n\n\nintensity_shallow <- orient_convert_to_intensity_matrix(activ_mat_shallow)\n\n\nsim_orienting_once <- function(matrix_size = 20, item_size = 25, prob = c(1/3, 1/3, 1/3), l_value1 = 0.6, l_value2 = 0) {\n  item_matrix <- gen_item_matrix(matrix_size = matrix_size, item_size = item_size, prob = prob)\n  item_matrix_copies <- gen_item_mat_copies(item_matrix)\n  orienting_memory <- gen_orienting_secondary_mem(item_matrix_copies, l_value1 = l_value1, l_value2 = l_value2)\n  probe_matrix <- gen_probes(item_matrix, prob = prob, max_num_of_copies = max_num_of_copies, num_of_traces_per_freq = num_of_traces_per_freq)\n  raw_activations <- calc_activs_for_mult_probes(probe_matrix, orienting_memory)\n  \n  shallow_activations <- c()\n  deep_activations <- c()\n  for(i in 1:nrow(raw_activations)) {\n  if(i %% 2 == 0) {\n    deep_activations <- rbind(deep_activations, raw_activations[i, ])\n  } else {\n    shallow_activations <- rbind(shallow_activations, raw_activations[i, ])\n  }\n  }\n  intensity_matrix <- rbind(orient_convert_to_intensity_matrix(shallow_activations), orient_convert_to_intensity_matrix(deep_activations))\n  return(intensity_matrix)\n  }\n  \n\nsim_orienting_multiple <- function(n_of_sim, matrix_size = 20, item_size = 25, prob = c(1/3, 1/3, 1/3), l_value1 = 0.6, l_value2 = 0) {\n  raw_intensity_matrix <- c()\n  for(i in 1:n_of_sim) {\n    temp_intensity <- sim_orienting_once(matrix_size = matrix_size, item_size = item_size, prob = prob, l_value1 = l_value1, l_value2 = l_value2)\n    raw_intensity_matrix <- cbind(raw_intensity_matrix, temp_intensity)\n  }\n  level_of_process <- c(rep(\"shallow\", max_num_of_copies + 1), rep(\"deep\", max_num_of_copies + 1))\n frequency <- rep(0:max_num_of_copies, 2)\n  intensity_df <- bind_cols(level_of_process, frequency, data.frame(raw_intensity_matrix)) %>% rename(level_of_process = ...1, frequency = ...2) %>% \n    pivot_longer(cols = starts_with(\"X\"), names_to = \"Drop\", values_to = \"Intensity\") %>% select(!Drop)\n  return(intensity_df)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\norient_intensity <- sim_orienting_multiple(1000)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n```\n:::\n\n```{.r .cell-code}\nsummarized_intensity <- orient_intensity %>% group_by(level_of_process, frequency) %>% summarize(mean_intensity = mean(Intensity))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'level_of_process'. You can override using\nthe `.groups` argument.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(summarized_intensity, aes(x = frequency, y = mean_intensity, group = level_of_process, color = level_of_process)) + geom_path() + geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThis graph is very different from Hintzman's. I think I must have fundamentally misunderstood something about how this simulation was carried out.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}