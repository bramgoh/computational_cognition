{
  "hash": "c1a012aa9100ab19229759463038f06a",
  "result": {
    "markdown": "---\ntitle: \"Reproducing Hintzman's MINERVA (Part 4)\"\nauthor: \"Bram Goh\"\ndate: \"2023-02-07\"\ncategories: [code]\nimage: \"Screenshot 2023-02-03 at 2.29.15 PM.png\"\n---\n\n\n# Generalizing the code for more flexibility and brief thoughts on cosine similarity\n\nFirst, I need to clean up my code: name variables such that I don't forget what they mean and define functions outside of other functions. Second, I need to generalize the code so that the number of categories is not hard coded .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nset.seed(30)\nnum_of_pattern_feat <- 13\nnum_of_name_feat <- 10\nnum_of_trace_feat <- num_of_name_feat + num_of_pattern_feat\nfeat_values <- c(rep(1, 50), rep(-1, 50))\nnum_to_distort <- 4\n\n\n\n\n# Generating prototype function\n  \ngen_proto <- function() {\n   proto <- sample(feat_values, num_of_trace_feat, replace = TRUE)\n   return(proto)\n}\n\n# Generating prototype copies --> yields proto_copies_matrix\n\ngen_proto_copies <- function(input_vector) {\n  full_proto_copies_matrix <- c()\n  for(i in input_vector) {\n    proto_single <- gen_proto()\n    proto_copies <- matrix(rep(proto_single, i), nrow = i, ncol = num_of_trace_feat, byrow = TRUE)\n    full_proto_copies_matrix <- rbind(full_proto_copies_matrix, proto_copies)\n  }\n  return(full_proto_copies_matrix)\n}\n\n# Generating traces in secondary memory with distortion --> yields memory_matrix\n\ngen_secondary_memory <- function(input_vector, proto_copies_matrix) {\n  total_num_traces_in_memory <- sum(input_vector)\n  matrix_of_ones_for_name <- matrix(1, nrow = total_num_traces_in_memory, ncol = num_of_name_feat)\n  matrix_of_pattern_distort <- t(replicate(n = total_num_traces_in_memory, sample(c(rep(1, num_of_pattern_feat - num_to_distort), rep(-1, num_to_distort)), num_of_pattern_feat)))\n  distort_filter <- cbind(matrix_of_ones_for_name, matrix_of_pattern_distort)\n  distorted_memories <- proto_copies_matrix * distort_filter\nreturn(distorted_memories)\n}\n  \n# Extracting unique prototypes (one for each category) --> yields proto_matrix\n\nextract_unique_proto <- function(input_vector, proto_copies_matrix) {\n  full_unique_proto_matrix <- c()\n  row_counter <- 0\n  for(i in input_vector) {\n    proto_current <- proto_copies_matrix[row_counter + 1, ]\n    full_unique_proto_matrix <- rbind(full_unique_proto_matrix, proto_current)\n    row_counter <- row_counter + i\n  }\nreturn(full_unique_proto_matrix)\n}\n\n# Generating probes from prototypes --> yields probe_matrix\n\ngen_probes_from_proto <- function(proto_matrix) {\n  matrix_of_ones_for_name <- matrix(1, nrow = nrow(proto_matrix), ncol = num_of_name_feat)\n  matrix_of_zeroes_for_pattern <- matrix(0, nrow = nrow(proto_matrix), ncol = num_of_pattern_feat)\n  probe_filter <- cbind(matrix_of_ones_for_name, matrix_of_zeroes_for_pattern)\n  probe_unique_matrix <- proto_matrix * probe_filter\n  return(probe_unique_matrix)\n}\n\n# Echo activation function --> yields activations_matrix\ncalc_echo_activations <- function(probe_matrix, memory_matrix) {\nfull_probe_activations_matrix <- c()\n  for(probe in 1:nrow(probe_matrix)) {\n    all_activations_for_each_probe <- c()\n    for(memory in 1:nrow(memory_matrix)) {\n      num_of_relevant_features <- 0\n      similarity_temp <- 0\n      for(feat in 1:num_of_trace_feat) {\n        current_product <- probe_matrix[probe, feat] * memory_matrix[memory, feat]\n        similarity_temp <- similarity_temp + current_product\n          if(probe_matrix[probe, feat] != 0 & memory_matrix[memory, feat] != 0) {\n            num_of_relevant_features <- num_of_relevant_features + 1\n          }\n    }\n    trace_similarity <- similarity_temp/num_of_relevant_features\n    trace_activation <- trace_similarity ^ 3\n    all_activations_for_each_probe <- c(all_activations_for_each_probe, trace_activation)\n  }\nfull_probe_activations_matrix <- rbind(full_probe_activations_matrix, all_activations_for_each_probe)\n}\nreturn(full_probe_activations_matrix)\n}\n\n# Echo intensity function --> yields intensity_matrix\ncalc_echo_intensity <- function(activations_matrix) {\n  full_intensity_matrix <- c()\n  for(probe in 1:nrow(activations_matrix)) {\n    echo_intensity_for_probe <- sum(activations_matrix[probe, ])\n    full_intensity_matrix <- c(full_intensity_matrix, echo_intensity_for_probe) \n  }\n  return(full_intensity_matrix)\n}\n\n# Echo content function --> yields content_matrix\n\ncalc_echo_content <- function(activations_matrix, memory_matrix) {\n  full_echo_content_matrix <- c()\n  for(probe in 1:nrow(activations_matrix)) {\n    echo_content_for_each_probe <- c()\n    for(feat in 1:num_of_trace_feat){\n      content_temp <- 0\n        for(memory in 1:nrow(memory_matrix)) {\n          current_product <- activations_matrix[probe, memory] * memory_matrix[memory, feat]\n          content_temp <- content_temp + current_product\n        }\n      echo_content_for_each_probe <- c(echo_content_for_each_probe, content_temp)\n    }\n    full_echo_content_matrix <- rbind(full_echo_content_matrix, echo_content_for_each_probe)\n  }\n  return(full_echo_content_matrix)\n}\n\n# Calculating prototype-echo correlation --> yields correlation_matrix\n\ncalc_proto_echo_corr <- function(proto_matrix, content_matrix) {\n  full_correlation_matrix <- c()\n  for(proto in 1:nrow(proto_matrix)) {\n    correlation_current <- cor(proto_matrix[proto, ], content_matrix[proto, ])\n    full_correlation_matrix <- c(full_correlation_matrix, correlation_current)\n  }\n  return(full_correlation_matrix)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_name_as_probe_calc_corr <- function(input_vector) {\n  proto_copies_matrix <- gen_proto_copies(input_vector)\n  memory_matrix <- gen_secondary_memory(input_vector, proto_copies_matrix)\n  proto_matrix <- extract_unique_proto(input_vector, proto_copies_matrix)\n  probe_matrix <- gen_probes_from_proto(proto_matrix)\n  activations_matrix <- calc_echo_activations(probe_matrix, memory_matrix)\n  content_matrix <- calc_echo_content(activations_matrix, memory_matrix)\n  correlation_matrix <- calc_proto_echo_corr(proto_matrix, content_matrix)\n  return(correlation_matrix)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulate_name_as_probe_calc_corr(c(3, 6, 9))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8021890 0.8395375 0.8793400\n```\n:::\n:::\n\n\nFinally, after much troubleshooting, it finally seems to work as intended. Time to simulate 20 subjects as Hintzman did and compare the mean prototype-echo correlations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_corr <- t(replicate(20, simulate_name_as_probe_calc_corr(c(3,6,9))))\ncorr_means <- c(mean(my_corr[ ,1]), mean(my_corr[ , 2]), mean(my_corr[ , 3]))\ncorr_sds <- c(sd(my_corr[ ,1]), sd(my_corr[ , 2]), sd(my_corr[ , 3]))\ncorr_means\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7777373 0.8415486 0.8586056\n```\n:::\n\n```{.r .cell-code}\ncorr_sds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04042487 0.02404416 0.01930278\n```\n:::\n:::\n\n\nInteresting that my mean prototype-echo correlations are higher than Hintzman's, while my standard deviations are smaller. I'll need to verify these values with Matt.\n\nAs an aside, we had a conversation about cosine similarity and how it doesn't capture differences in vector length, only in the difference in degree.\n\n-   What implications are there for memory? Hintzman conceptualizes memories as -1s or 1s, similar to how computers are able to code complex information into 0s and 1s. Thus, could vector length be already a built-in consideration, as one of the many features?\n\n-   Given the bar chart diagram Matt drew, where the two bar charts are identical in their positive and negative direction figuration, but differ in the length of the bar, that makes me recall an explanation of correlation similarity that I learnt in class. Do both cosine and correlation similarity not capture vector length?\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}